import requests
import feedparser
import os
import json
import time
import re
from html import unescape
from datetime import datetime, timedelta

# Misskey API ì„¤ì •
MISSKEY_URL = "https://it.21stcentury.day"
API_TOKEN = "NX2YWgEHHV4iUIARk0rhUhqDA8ttvzjm"

# í…ìŠ¤íŠ¸ ì œí•œ í•¨ìˆ˜
def truncate_text(text, max_length=3000):
    if len(text) > max_length:
        return text[:300] + "..."
    return text

def strip_html_tags(text):
    # HTML íƒœê·¸ ì œê±°
    clean = re.sub(r'<.*?>', '', text)
    # HTML ì—”í‹°í‹°ë¥¼ ì¼ë°˜ë¬¸ìë¡œ ë³€í™˜
    return unescape(clean)

# CWë¡œ ë…¸íŠ¸ ê²Œì‹œ
def post_to_misskey_with_cw(cw_text, note_content):
    url = f"{MISSKEY_URL}/api/notes/create"
    headers = {
        "Content-Type": "application/json",
    }
    note_content = truncate_text(strip_html_tags(note_content))
    payload = {
        "i": API_TOKEN,
        "text": note_content,  # ë³¸ë¬¸
        "cw": cw_text,         # CW ì œëª©
    }
    response = requests.post(url, json=payload, headers=headers)

    # ì‘ë‹µ í™•ì¸
    if response.status_code == 200:
        print("Note posted successfully with CW!")
    else:
        print(f"Failed to post note: {response.status_code} - {response.text}")


# RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸°
def fetch_recent_rss_feed(url):
    feed = feedparser.parse(url)
    entries = []

    now = datetime.now()

    for entry in feed.entries:
        try:
            if 'published' in entry:
                entry_date = datetime(*entry.published_parsed[:6])
            elif 'updated' in entry:
                entry_date = datetime(*entry.updated_parsed[:6])
            else:
                continue
        except (AttributeError, ValueError):
            continue

        if now - entry_date < timedelta(days=1):
            entries.append({
                "title": entry.title,
                "link": entry.link,
                "summary": entry.summary,
                "date": entry_date
            })

    return entries

def process_rss_feed(url):
    posted_entries = load_posted_entries()
    new_entries = fetch_recent_rss_feed(url)

    for entry in new_entries:
        if entry["link"] not in posted_entries:
            cw_text = f"ìƒˆ ê¸€: {entry['title']}"
            note_content = (
                f"ğŸ”— {entry['link']}\n\n"
                f"{entry['summary']}"
            )

            post_to_misskey_with_cw(cw_text, note_content)

            posted_entries.append(entry["link"])
            save_posted_entries(posted_entries)


# ì´ë¯¸ ê²Œì‹œëœ í•­ëª© ì¶”ì 
POSTED_ENTRIES_FILE = "posted_entries.json"

def load_posted_entries():
    if os.path.exists(POSTED_ENTRIES_FILE):
        with open(POSTED_ENTRIES_FILE, "r") as file:
            return json.load(file)
    return []

def save_posted_entries(entries):
    with open(POSTED_ENTRIES_FILE, "w") as file:
        json.dump(entries, file)

# RSS URL ì„ ì–¸
rss_url = "https://theanarchistlibrary.org/feed"

# ë°˜ë³µ ì‹¤í–‰
while True:
    process_rss_feed(rss_url)
    time.sleep(3600)  # 1ì‹œê°„ ëŒ€ê¸°
